name: Trigger and compare benchmarks
on:
  workflow_call:
  workflow_dispatch:

env:
  DEFAULT_REFERENCE_VERSION: main

jobs:
  benchmark:
    name: Benchmark current version
    uses: ./.github/workflows/run_benchmarks.yaml
    with:
      ref: ${{ github.sha }}

  check_reference:
    name: Check for reference benchmark results
    runs-on: ubuntu-24.04
    outputs:
      reference_sha: ${{ steps.obtain_ref.outputs.reference_sha }}
      reference_results_available: ${{ steps.check_ref_results.outputs.available }}
      artifact_id: ${{ steps.check_ref_results.outputs.artifact_id }}
    steps:
      - uses: actions/create-github-app-token@67018539274d69449ef7c02e8e71183d1719ab42 # v2.1.4
        id: benchmark_app_token
        with:
          app-id: ${{ vars.OVERLAP_BENCHMARK_APP_ID }}
          private-key: ${{ secrets.OVERLAP_BENCHMARK_PRIVATE_KEY }}

      - name: Obtain SHA of reference version
        id: obtain_ref
        if: ${{ github.event_name == 'pull_request' }}
        run: |
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            reference_sha="${{ github.event.pull_request.base.sha }}"
          else
            reference_sha=$(git rev-parse origin/"$DEFAULT_REFERENCE_VERSION")
          fi

          echo "reference_sha=${reference_sha}" >> "$GITHUB_OUTPUT"

      - name: Check if benchmark results for reference version exist
        id: check_ref_results
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          github-token: ${{ steps.benchmark_app_token.outputs.token }}
          script: |
            const ref = "${{ steps.obtain_ref.outputs.reference_sha }}";
            const artifact_name = "benchmarks-" + ref;
            const request = await github.rest.actions.listArtifactsForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: artifact_name,
            });

            if (request.data.total_count) {
              console.log(`Benchmark results for revision '${ref}' exist.`);
              core.setOutput("artifact_id", request.data.artifacts[0].id);
            } else {
              console.log(`Benchmark results for revision '${ref}' do not exist, requesting run.`);
            }

            core.setOutput("available", request.data.total_count != 0);

  benchmark_reference:
    name: Benchmark reference version
    needs: check_reference
    if: ${{ !fromJSON(needs.check_reference.outputs.reference_results_available) }}
    uses: ./.github/workflows/run_benchmarks.yaml
    with:
      ref: ${{ needs.check_reference.outputs.reference_sha }}
      allow_failure: true

  compare_benchmarks:
    name: Compare benchmark results
    needs: [benchmark, benchmark_reference, check_reference]
    if: ${{ always() && (fromJSON(needs.check_reference.outputs.reference_results_available) || needs.benchmark_reference.outputs.outcome == 'success') }}
    runs-on: ubuntu-24.04
    steps:
      - name: Dependencies
        run: |
          python -m pip install pyperf

      - uses: actions/create-github-app-token@67018539274d69449ef7c02e8e71183d1719ab42 # v2.1.4
        id: benchmark_app_token
        with:
          app-id: ${{ vars.OVERLAP_BENCHMARK_APP_ID }}
          private-key: ${{ secrets.OVERLAP_BENCHMARK_PRIVATE_KEY }}

      - name: Obtain archived benchmark results for reference version
        if: ${{ fromJSON(needs.check_reference.outputs.reference_results_available) }}
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          github-token: ${{ steps.benchmark_app_token.outputs.token }}
          script: |
            const fs = require("fs");
            const child_process = require("child_process");

            const ref = "${{ needs.check_reference.outputs.reference_sha }}";
            const artifact_id = ${{ needs.check_reference.outputs.artifact_id }};
            const artifact_name = `benchmarks-${ref}`;
            const request = await github.rest.actions.downloadArtifact ({
              owner: context.repo.owner,
              repo: context.repo.repo,
              artifact_id: artifact_id,
              archive_format: "zip",
            });

            fs.writeFileSync(artifact_name, Buffer.from(request.data));
            child_process.execSync(`unzip -o ${artifact_name} -d ${ref}`);

      - name: Obtain new benchmark results for reference version
        if: ${{ !fromJSON(needs.check_reference.outputs.reference_results_available) }}
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0
        with:
          pattern: benchmarks-*-${{ needs.check_reference.outputs.reference_sha }}
          path: ${{ needs.check_reference.outputs.reference_sha }}
          merge-multiple: true

      - name: Obtain benchmark results for current version
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0
        with:
          pattern: benchmarks-*-${{ github.sha }}
          path: ${{ github.sha }}
          merge-multiple: true

      - name: Compare benchmark results
        run: |
          touch report.md
          declare -A languages=(["cpp"]="C++" ["python"]="Python")
          for key in "${!languages[@]}"
          do
            echo "Processing benchmark results for $key..."
            echo "## ${languages[$key]} benchmark results" >> report.md

            mv "${{ github.sha }}/benchmarks-$key.json" Current
            if [[ -f "${{ needs.check_reference.outputs.reference_sha }}/benchmarks-$key.json" ]]; then
              mv "${{ needs.check_reference.outputs.reference_sha }}/benchmarks-$key.json" Reference
            else
              cp Current Reference
            fi

            python -m pyperf compare_to --table --table-format md Reference Current >> report.md
          done


      - name: Check for existing PR comment
        if: ${{ github.event_name == 'pull_request' }}
        uses: peter-evans/find-comment@3eae4d37986fb5a8592848f6a574fdf654e61f9e # v3.1.0
        id: find_existing_comment
        with:
          issue-number: ${{ github.event.pull_request.number }}
          comment-author: "overlap-benchmarks[bot]"
          body-includes: "C++ benchmark results"

      - name: Create/update PR comment
        if: ${{ github.event_name == 'pull_request'}}
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          github-token: ${{ steps.benchmark_app_token.outputs.token }}
          script: |
            const fs = require("fs");
            const report = fs.readFileSync("./report.md")
              .toString()
              .replace(/Current/, "Current (${{ github.sha }})")
              .replace(/Reference/, "Reference (${{ needs.check_reference.outputs.reference_sha }})");

            try {
              if ("${{steps.find_existing_comment.outputs.comment-id}}" == "") {
                const result = await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.issue.number,
                  body: report,
                });
                return result.data;
              }

              const result = await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: "${{steps.find_existing_comment.outputs.comment-id}}",
                body: report,
              });
              return result.data;
            } catch (err) {
              core.setFailed(`Request failed with error ${err}`);
            }

      - name: Report via annotation
        if: ${{ github.event_name != 'pull_request' }}
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const fs = require('fs');
            core.notice(fs.readFileSync('./report.md'));
